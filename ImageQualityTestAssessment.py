# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'main.ui'
#
# Created by: PyQt5 UI code generator 5.15.11
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.



# Histogram function outside the class
# -*- coding: utf-8 -*-

from PyQt5 import QtCore, QtGui, QtWidgets
import sys
import time
from PyQt5.QtWidgets import (QApplication, QMainWindow, QPushButton, QLabel, QVBoxLayout,
                             QFileDialog, QGraphicsView, QGraphicsScene, QWidget, QDialog)
from PyQt5.QtGui import QPixmap, QImage
from PyQt5.QtCore import Qt
import cv2
import numpy as np
import matplotlib.pyplot as plt
from PyQt5.uic import loadUi
from PyQt5 import uic
from PyQt5.QtCore import QTimer
from Histogram import histogram, plothistogram
from SecondForm1 import SecondForm
from MyForm import MyForm
from math import sqrt
from PyQt5.QtCore import QThread, pyqtSignal, QTimer
from threading import *
K = 3



def Convolution(input, kernel, kernel2, output, height, width, K=3):
    for i in range(height):
        for j in range(width):
            sumX = 0
            sumY = 0
            for i1 in range(-1, 2):  
                for j1 in range(-1, 2):
                    ii = i + i1
                    jj = j + j1
                    if ii >= 0 and ii < height and jj >= 0 and jj < width:
                        
                        sumX += int(input[ii * width + jj]) * kernel[(i1 + 1) * 3 + (j1 + 1)]
                        sumY += int(input[ii * width + jj]) * kernel2[(i1 + 1) * 3 + (j1 + 1)]
            
           
            sum = sqrt(sumX * sumX + sumY * sumY)
            if sum > 255:
                sum = 255 
            output[i * width + j] = int(sum)


def histogram(input, output, height, width):
        for i in range(height):
            for j in range(width):
                count = input[i * width + j]
                output[count] += 1

def plothistogram(histogramB, histogramG, histogramR):
        hist_w = 300
        hist_h = 412
        bin_w = round(hist_w / 256)

        histImage = np.zeros((hist_h, hist_w, 3), dtype=np.uint8)

        max_value = max(max(histogramB), max(histogramG), max(histogramR))

        for i in range(256):
            histogramB[i] = int((histogramB[i] / max_value) * hist_h)
            histogramG[i] = int((histogramG[i] / max_value) * hist_h)
            histogramR[i] = int((histogramR[i] / max_value) * hist_h)

        for i in range(1, 256):
            cv2.line(histImage, (bin_w * (i - 1), hist_h - histogramB[i - 1]),
                (bin_w * i, hist_h - histogramB[i]), (255, 0, 0), 2)

            cv2.line(histImage, (bin_w * (i - 1), hist_h - histogramG[i - 1]),
                (bin_w * i, hist_h - histogramG[i]), (0, 255, 0), 2)

            cv2.line(histImage, (bin_w * (i - 1), hist_h - histogramR[i - 1]),
                (bin_w * i, hist_h - histogramR[i]), (0, 0, 255), 2)

        return histImage

class Ui_MainWindow(QMainWindow):

    def __init__(self):
        super().__init__()
        uic.loadUi('main.ui',self)
        
        # Assuming 'self' is a QMainWindow or QWidget
        self.button1.setStyleSheet("background-color:rgb(247, 173, 26);")
       # self.button2.setStyleSheet("background-color:rgb(247, 173, 26);")
        self.button3.setStyleSheet("background-color:rgb(247, 173, 26);")
        self.button4.setStyleSheet("background-color:rgb(247, 173, 26);")
        self.button5.setStyleSheet("background-color:rgb(247, 173, 26);")
        self.button6.setStyleSheet("background-color:rgb(247, 173, 26);")
        self.button7.setStyleSheet("background-color:rgb(247, 173, 26);")
        #self.label_8.setStyleSheet("background-color:rgb(247, 173, 26);")
        #self.label_7.setStyleSheet("background-color:rgb(247, 173, 26);")
        self.button1.setCheckable(True)
        #self.button2.setCheckable(True)
        self.button6.setCheckable(True) 
        self.button5.setCheckable(True) 
        self.button1.clicked.connect(self.open_file)
        #self.button2.clicked.connect(self.DisplayVideo)
        self.button4.clicked.connect(self.EqualizeHisto)
        self.button7.clicked.connect(self.sharpness)
        self.button3.setVisible(False)
        self.button4.setVisible(False)
        self.button5.setVisible(False)
        self.button6.setVisible(False)
        self.button7.setVisible(False)
        self.label.setVisible(False)
        self.label_2.setVisible(False)
        self.label_3.setVisible(False)
        self.label_4.setVisible(False)
        self.label_5.setVisible(False)
        self.label_6.setVisible(False)
        self.label_9.setVisible(False)
        self.label_10.setVisible(False)
        self.label_11.setVisible(False)
        self.label_12.setVisible(False)
        self.label_13.setVisible(False)
        self.label_14.setVisible(False)

        
           
        self.video_file_path = None
        self.image_file_path = None
        self.fps = 0
        self.count = 0
        self.x, self.y, self.w, self.h = 0, 0, 0, 0  # ROI coordinates
        self.timer = None
        self.is_paused = False  # New state variable to track pause status
        self.frame = None
        self.timer = QTimer(self) 
        self.params = 0 
        # self.button3.clicked.connect(self.SobelCheck)
        self.output =None
        
       
        
        self.show()
     
       
        
        
       

        self.retranslateUi(MainWindow)
        QtCore.QMetaObject.connectSlotsByName(MainWindow)
    

    def retranslateUi(self, MainWindow):
        _translate = QtCore.QCoreApplication.translate
        MainWindow.setWindowTitle(_translate("MainWindow", "MainWindow"))
        self.button1.setText(_translate("MainWindow", "Image/Video"))
        #self.button2.setText(_translate("MainWindow", "Video"))
        self.button3.setText(_translate("MainWindow", "Sobel"))
        self.button4.setText(_translate("MainWindow", "Equalize Histogram"))
        self.button5.setText(_translate("MainWindow", "Crop"))
        self.button6.setText(_translate("MainWindow", "Extract Frame"))
        self.button7.setText(_translate("MainWindow", "Sharpness"))
        self.label.setText(_translate("MainWindow", "Image"))
        self.label_2.setText(_translate("MainWindow", "Histogram"))
        self.label_3.setText(_translate("MainWindow", "Equalized Image "))
        self.label_4.setText(_translate("MainWindow", "Equalized Histogram"))
        self.label_5.setText(_translate("MainWindow", "Sobel Filter "))
        self.label_9.setText(_translate("MainWindow", "Image/Video"))
        self.label_10.setText(_translate("MainWindow", "Histogram"))
        self.label_11.setText(_translate("MainWindow", "Equalized Image"))
        self.label_12.setText(_translate("MainWindow", "Sobel Filter"))
        self.label_13.setText(_translate("MainWindow", "Equalized Histogram"))
        self.label_14.setText(_translate("MainWindow", "Sharpened Image"))

    


   
    def open_file(self):
        self.label.clear()
        self.label_2.clear()
        self.label_3.clear()
        self.label_4.clear()
        self.label_5.clear()
        self.label_6.clear()
        self.label_9.setVisible(False)
        self.label_10.setVisible(False)
        self.label_11.setVisible(False)
        self.label_12.setVisible(False)
        self.label_13.setVisible(False)
        self.label_14.setVisible(False)
        self.button3.setVisible(False)
        self.button4.setVisible(False)
        self.button5.setVisible(False)
        self.button6.setVisible(False)
        self.button7.setVisible(False)
        file_path, _ = QFileDialog.getOpenFileName(self, 'Open File', '', 'All Files (*);;Image Files (*.jpg);;Video Files (*.mp4)')

        if file_path:
            if file_path.lower().endswith('.jpg'):
                self.label_9.setText("Image")
                self.displayImage(file_path)
                self.button3.clicked.connect(self.SobelImage)
            elif file_path.lower().endswith('.mp4'):
                self.label_9.setText("Video")
                self.DisplayVideo(file_path)
                self.button3.clicked.connect(self.SobelVideo)
                self.label_2.setVisible(False)
                self.label_3.setVisible(False)
                self.label_4.setVisible(False)
                self.label_6.setVisible(False)

        else:
            sys.exit()
    

    def displayImage(self,image_path):
        self.button3.setVisible(True)
        self.button4.setVisible(True)
        self.button7.setVisible(True)
        self.label_9.setVisible(True)
        self.label_10.setVisible(True)
        self.label.setVisible(True)
        self.label_2.setVisible(True)
       
      
       
        
        if image_path:
            self.image_file_path = image_path
            self.img = cv2.imread(self.image_file_path)
            if self.img is None:
                print("Could not open or find the image")
                return
        
       
        self.display_image(self.img)
        self.output = self.img
        rows, cols, channels = self.img.shape
     
        bluechannel, greenchannel, redchannel = cv2.split(self.img)
       # cv2.imshow("image", self.img)

        blue = bluechannel.flatten()
        green = greenchannel.flatten()
        red = redchannel.flatten()

        grad_B = np.zeros(256, dtype=int)
        grad_G = np.zeros(256, dtype=int)
        grad_R = np.zeros(256, dtype=int)

        histogram(blue,grad_B, rows, cols)
        histogram(green,grad_G, rows, cols)
        histogram(red,grad_R, rows, cols)

        histImage = plothistogram(grad_B, grad_G, grad_R) 
        histImage = cv2.cvtColor(histImage,cv2.COLOR_BGR2RGB)
    
        height, width, channel = histImage.shape
        bytes_per_line = 3 * width
        q_image = QImage(histImage.data, width, height, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)

        self.label_2.setPixmap(pixmap)
        self.label_2.setScaledContents(True)
    
    def DisplayVideo(self, video_path):
        self.button3.setVisible(True)
        self.button5.setVisible(True)
        self.button6.setVisible(True)
        self.label.setVisible(True)
        self.label_9.setVisible(True)
        
       

        if video_path:
            self.video_file_path = video_path
            self.cap = cv2.VideoCapture(video_path)
            self.fps = int(self.cap.get(cv2.CAP_PROP_FPS))
            self.count = 0

        if not self.cap.isOpened():
            print("Error opening video stream or file")
            return
        
        ret, frame = self.cap.read()
        if not ret:
            print("Error reading the first frame")
            return
        
        
        
        self.timer.timeout.connect(self.process_frame)
        self.timer.start(int((1/self.fps)*1000))

    def crop_video(self):
        if self.button5.isChecked():
            
            if self.frame is not None:
                roi = cv2.selectROI("Select ROI", self.frame, fromCenter=False, showCrosshair=True)
                cv2.setWindowProperty("Select ROI", cv2.WND_PROP_TOPMOST, 1)
                if roi == (0, 0, 0, 0):
                    print("No ROI selected")
                    return
                self.params= roi

                cv2.destroyAllWindows()
        
        return self.params
                

    def process_frame(self):
        # if self.is_paused:
        #     return
        ret, self.frame = self.cap.read()
        
        if self.frame is None:
            self.timer.stop()
            print("Frame is None,skipping...")
            return
        
        params = self.crop_video()

        if params != 0:
            self.x, self.y, self.w, self.h = params
            cropped_frame = self.frame[self.y:self.y+self.h, self.x:self.x+self.w]
            
            # self.is_paused = True  
            self.update_frame(cropped_frame)
            self.button5.setChecked(False)
            
        else:
            # self.is_paused = False  
            self.update_frame(self.frame)
        

        if self.button6.isChecked():
            filename = f"frame_{self.count}.jpg"
            cv2.imwrite(filename, self.frame)
            self.count += 1


    def update_frame(self, frame):
        if frame is None:
            print("Empty frame, skipping...")
            return

    
        if frame.shape[0] == 0 or frame.shape[1] == 0:
            print("Frame has invalid dimensions, skipping...")
            return

    
        try:
            frame1 = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        except Exception as e:
            print(f"Error converting frame: {e}")
            return

        height, width, channel = frame1.shape
        #print(height,width)
        bytes_per_line = 3 * width
        q_image = QImage(frame1.data, width, height, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)

        self.label.setPixmap(pixmap)
        self.label.setScaledContents(True)
    def update_sobelframe(self, frame):
        if frame is None:
            print("Empty frame, skipping...")
            return

    
        if frame.shape[0] == 0 or frame.shape[1] == 0:
            print("Frame has invalid dimensions, skipping...")
            return

    
        try:
            frame1 = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        except Exception as e:
            print(f"Error converting frame: {e}")
            return

        height, width, channel = frame1.shape
        #print(height,width)
        bytes_per_line = 3 * width
        q_image = QImage(frame1.data, width, height, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)

        self.label_5.setPixmap(pixmap)
        self.label_5.setScaledContents(True)




    def SobelVideo(self):
        self.label_5.setVisible(True)
        self.label_12.setVisible(True)
        if not self.video_file_path:
             print("No video file path selected")
             return
    

        file = self.video_file_path
        self.cap = cv2.VideoCapture(file)

        if not self.cap.isOpened():
            print("Error opening video stream or file")
            return 

 
        self.timer.timeout.connect(self.process_Sobelframe)
        self.timer.start(int((1/self.fps)*1000))
        
    def process_Sobelframe(self):
        # if self.is_paused:
        #     return
        ret, self.frame = self.cap.read()
        
        if self.frame is None:
            self.timer.stop()
            print("Frame is None,skipping...")
            return
        
        Kernel = np.array([-1, 0, 1, -2, 0, 2, -1, 0, 1]).reshape((3, 3))
        Kernel2 = np.array([-1, -2, -1, 0, 0, 0, 1, 2, 1]).reshape((3, 3))
        rows, cols = self.frame.shape[:2]
        bluechannel, greenchannel, redchannel = cv2.split(self.frame)
        
        grad_B = cv2.filter2D(bluechannel, -1, Kernel) + cv2.filter2D(bluechannel, -1, Kernel2)
        grad_G = cv2.filter2D(greenchannel, -1, Kernel) + cv2.filter2D(greenchannel, -1, Kernel2)
        grad_R = cv2.filter2D(redchannel, -1, Kernel) + cv2.filter2D(redchannel, -1, Kernel2)
        
        final_output = cv2.merge([grad_B, grad_G, grad_R])
        #final_output = cv2.cvtColor(final_output, cv2.COLOR_BGR2RGB)

        params = self.crop_video()

        if params != 0:
            self.x, self.y, self.w, self.h = params
            cropped_frame = final_output[self.y:self.y+self.h, self.x:self.x+self.w]
            
            # self.is_paused = True  
            self.update_sobelframe(cropped_frame)
            self.button5.setChecked(False)
            
        else:
            # self.is_paused = False  
            self.update_sobelframe(final_output)
        

        if self.button6.isChecked():
            filename = f"frame_{self.count}.jpg"
            cv2.imwrite(filename, self.frame)
            self.count += 1


    def SobelImage(self):
        self.label_5.setVisible(True)
        self.label_12.setVisible(True)
        if not self.image_file_path:
             print("No video file path selected")
             return
        path = self.image_file_path
        if path:
            self.img = cv2.imread(path)
               
        rows, cols, channels = self.img.shape

    
        bluechannel, greenchannel, redchannel = cv2.split(self.img)

    
        blue = bluechannel.flatten()
        green = greenchannel.flatten()
        red = redchannel.flatten()

        Kernel = [-1, 0, 1, -2, 0, 2, -1, 0, 1]
        Kernel2 = [-1, -2, -1, 0, 0, 0, 1, 2, 1]

 
        grad_B = np.zeros_like(blue)
        grad_G = np.zeros_like(green)
        grad_R = np.zeros_like(red)

   
        Convolution(blue, Kernel, Kernel2, grad_B, rows, cols)
        Convolution(green, Kernel, Kernel2, grad_G, rows, cols)
        Convolution(red, Kernel, Kernel2, grad_R, rows, cols)

  
        grad_B = grad_B.reshape((rows, cols))
        grad_G = grad_G.reshape((rows, cols))
        grad_R = grad_R.reshape((rows, cols))

   
        final_output = cv2.merge([grad_B, grad_G, grad_R])

        final_output = cv2.cvtColor(final_output,cv2.COLOR_BGR2RGB)
        self.output = final_output
        height, width, channel = final_output.shape
        bytes_per_line = 3 * width
        q_image = QImage(final_output.data, width, height, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)

        self.label_5.setPixmap(pixmap)
        self.label_5.setScaledContents(True)

    
  
    
    def EqualizeHisto(self):
        self.label_3.setVisible(True)
        self.label_4.setVisible(True)
        self.label_11.setVisible(True)
        self.label_13.setVisible(True)
        if not self.image_file_path:
             print("No video file path selected")
             return
        path = self.image_file_path
        if path:
            self.img = cv2.imread(path)
        rows, cols, channels = self.img.shape
        bluechannel, greenchannel, redchannel = cv2.split(self.img)
        #cv2.imshow("image",img)
 
        blue = bluechannel.flatten()
        green = greenchannel.flatten()
        red = redchannel.flatten()
  
        grad_B = np.zeros(256, dtype=int)
        grad_G = np.zeros(256, dtype=int)
        grad_R = np.zeros(256, dtype=int)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))
        blue_eq = clahe.apply(blue)
        green_eq =clahe.apply(green)
        red_eq = clahe.apply(red)
#    blue_eq = cv2.equalizeHist(blue)
#    green_eq = cv2.equalizeHist(green)
#    red_eq= cv2.equalizeHist(red)
 
        histogram(blue_eq, grad_B, rows, cols)
        histogram(green_eq, grad_G, rows, cols)
        histogram(red_eq, grad_R, rows, cols)
        blue_equalized_image = blue_eq.reshape((rows, cols))
        green_equalized_image = green_eq.reshape((rows, cols))
        red_equalized_image = red_eq.reshape((rows, cols))
   
        final_output = cv2.merge([blue_equalized_image, green_equalized_image, red_equalized_image])
   
        final_output =cv2.cvtColor(final_output,cv2.COLOR_BGR2RGB)
        self.output = final_output
        height, width, channel = final_output.shape
        bytes_per_line = 3 * width
        q_image = QImage(final_output.data, width, height, bytes_per_line, QImage.Format_RGB888)
        pixmap1 = QPixmap.fromImage(q_image)

        self.label_3.setPixmap(pixmap1)
        self.label_3.setScaledContents(True)
   
        hist_image = plothistogram(grad_B, grad_G, grad_R)
        hist_image = cv2.cvtColor(hist_image,cv2.COLOR_BGR2RGB)
        height, width, channel = hist_image.shape
        bytes_per_line = 3 * width
        q_image = QImage(hist_image.data, width, height, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)

        self.label_4.setPixmap(pixmap)
        self.label_4.setScaledContents(True)
    # Sharpening an image   
    def sharpness(self):
        self.label_6.setVisible(True)
        self.label_14.setVisible(True)
        second_form = SecondForm()
        
        path = second_form.get_path()
        if path:
            self.img = cv2.imread(path)
        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])#Sharpening Kernel Matrix
        self.blurred_img = cv2.GaussianBlur(self.img, (3, 3), 0)
    
        roi = cv2.selectROI("Select ROI", self.blurred_img, fromCenter=False, showCrosshair=True)#Creates an ROI for sharpening
        if roi == (0, 0, 0, 0):
            print("No ROI selected")
        
        x, y, w, h = roi
        cv2.destroyAllWindows()
        imageroi = self.blurred_img[y:y+h, x:x+w]
        sharpenedRoi = cv2.filter2D(imageroi, -1, kernel)
    
        sharpenedImage = self.img.copy()
        sharpenedImage[y:y+h, x:x+w] = sharpenedRoi
        sharpenedImage  = cv2.cvtColor(sharpenedImage,cv2.COLOR_BGR2RGB)
        self.output = sharpenedImage
        sharpenedRoi = cv2.cvtColor(sharpenedRoi,cv2.COLOR_BGR2RGB)
        height, width, channel = sharpenedRoi.shape
        bytes_per_line = 3 * width
        q_image = QImage(sharpenedRoi.data, width, height, bytes_per_line, QImage.Format_RGB888)#Converts the image into qimage image format
        pixmap = QPixmap.fromImage(q_image)

        self.label_6.setPixmap(pixmap)#sets the label for the image
        self.label_6.setScaledContents(True)


    

    def display_image(self, image):
        # Convert image to Qt format
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)#converts the BGR to RGB Format
        height, width, channel = image.shape
        bytes_per_line = 3 * width
        q_image = QImage(image.data, width, height, bytes_per_line, QImage.Format_RGB888)
        pixmap = QPixmap.fromImage(q_image)
        
        self.label.setPixmap(pixmap)
        self.label.setScaledContents(True)

    # def display_outimage(self, image):
    #     # Convert image to Qt format
    #     self.output = cv2.cvtColor(self.output, cv2.COLOR_BGR2RGB)#converts the BGR to RGB Format
    #     height, width, channel = self.output.shape
    #     bytes_per_line = 3 * width
    #     q_image = QImage(self.output.data, width, height, bytes_per_line, QImage.Format_RGB888)
    #     pixmap = QPixmap.fromImage(q_image)

    #     self.label_5.setPixmap(pixmap)
    #     self.label_5.setScaledContents(True)
  

if __name__ == "__main__":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    MainWindow = QtWidgets.QMainWindow()
    ui = Ui_MainWindow()
    #MainWindow.show()
    sys.exit(app.exec_())
